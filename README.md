# ğŸ“˜ Azure Data Factory for Data Engineers â€” Covid-19 Analytics Project

This repository contains a full **end-to-end Azure Data Engineering project** built around real Covid-19 datasets from **ECDC (European Centre for Disease Prevention and Control)** and **Eurostat**.

The project demonstrates real-world enterprise data engineering skills:

- Designing & orchestrating data pipelines
- Ingesting data from HTTP APIs & Blob Storage
- Applying transformations using ADF Mapping Data Flows & Databricks
- Creating analytics-ready star schema tables in Azure SQL
- Building a Power BI report for Covid-19 insights
- Implementing scheduled pipelines, validations, monitoring, and alerts

---

# ğŸ—ï¸ Solution Architecture

![Covid-19 Architecture](assets/Untitled%20Diagram-Page-6.drawio.png)

---

# ğŸ“ Repository Structure
azure-data-factory-covid19-project/
â”‚
â”œâ”€â”€ assets/                             # Architecture diagrams & pipeline screenshots
â”‚
â”œâ”€â”€ databricks_notebooks/
â”‚   â”œâ”€â”€ nb_transform_population_data.ipynb
â”‚   â””â”€â”€ nb_transform_testing_data.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input_data/
â”‚   â”‚   â”œâ”€â”€ ecdc_data/
â”‚   â”‚   â””â”€â”€ eurostat_data/
â”‚   â”‚
â”‚   â”œâ”€â”€ lookup_data/
â”‚   â”‚   â”œâ”€â”€ country_lookup.csv
â”‚   â”‚   â””â”€â”€ dim_date.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ ecdc_data/
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ ecdc/
â”‚   â”‚   â””â”€â”€ population/
â”‚   â”‚
â”‚   â”œâ”€â”€ sql_scripts/
â”‚       â””â”€â”€ create_covid_tables_ddl.sql
â”‚
â”œâ”€â”€ power_bi_reports/
â”‚   â””â”€â”€ Covid-19 Trends By Country.pbix
â”‚
â””â”€â”€ README.md

---

# 1ï¸âƒ£ Environment Setup

To run this project end-to-end, the following Azure resources were provisioned:

---

### ğŸ”¹ Azure Storage Account (Blob + ADLS Gen2)

- Enabled **hierarchical namespace**
- Used for:
  - `/input_data` (raw files before ingestion)
  - `/raw` (ADF ingestion zone)
  - `/processed` (transformed zone)
  - `/lookup_data` (reference files)

---

### ğŸ”¹ Azure Data Factory

Acts as the **orchestration engine**, responsible for:

- Ingesting ECDC & Eurostat files
- Executing Databricks notebooks
- Running Mapping Data Flows
- Loading data into SQL DB
- Pipeline scheduling & monitoring

**ADF Pipelines:**  
![Pipelines](assets/Screenshot%202025-11-14%20220923.png)

---

### ğŸ”¹ Azure Databricks

Used for transformations that require heavy compute:

- Parsing population dataset
- Cleaning testing dataset
- Creating aggregated age groups
- Writing curated outputs to ADLS

![Databricks pipeline activity](assets/Screenshot%202025-11-14%20221008.png)

---

### ğŸ”¹ Azure SQL Database

Serves as the **analytics database** supporting Power BI dashboards. Tables include:

- `dim_country`
- `dim_date`
- `fact_cases_deaths`
- `fact_hospital_admissions_daily`
- `fact_hospital_admissions_weekly`
- `fact_testing`
- `dim_population_age_group`

SQL DDL script located here:  
`/data/sql_scripts/create_covid_tables_ddl.sql`

---

### ğŸ”¹ Azure Key Vault

Securely stores:

- Service Principal credentials
- Storage account keys
- SQL credentials

---

# 2ï¸âƒ£ Raw Data Ingestion Pipelines

---

## âœ” Ingest ECDC Data (HTTP â†’ ADLS Gen2)

ADF dynamically retrieves all available CSV files using:

- **Lookup**
- **ForEach**
- **Copy Activity**

![ECDC pipeline](assets/Screenshot%202025-11-14%20221208.png)

---

## âœ” Ingest Population Data (Blob â†’ ADLS Gen2)

Pipeline performs:

- File existence check
- Metadata validation
- Copy to raw zone
- Delete source file if valid

![Population pipeline](assets/Screenshot%202025-11-14%20231740.png)

---

# 3ï¸âƒ£ Data Transformation (ETL/ELT)

---

## ğŸ“Œ ADF Mapping Data Flows

### ğŸ”¹ Transform Hospital Admissions

Creates both **Daily** and **Weekly** datasets:

![Hospital Data Flow](assets/Screenshot%202025-11-14%20221122.png)

Includes:

- Pivot
- Aggregations
- Join with country lookup
- Weekly rollups

---

### ğŸ”¹ Transform Cases & Deaths

![Cases Data Flow](assets/Screenshot%202025-11-14%20221152.png)

Steps include:

- Filter to European region
- Pivot indicators
- Lookup country metadata
- Output curated dataset

---

## ğŸ“Œ Databricks Transformations

Stored in `/databricks_notebooks/`

---

### ğŸ”¹ Population Transformation Notebook

`nb_transform_population_data.ipynb`

Key steps:

- Load `.tsv.gz`
- Unpivot mixed columns
- Map geo codes
- Aggregate to age groups
- Write processed output

---

### ğŸ”¹ Testing Data Notebook

`nb_transform_testing_data.ipynb`

- Clean daily testing data
- Add ISO week numbers
- Join dim tables
- Write curated datasets

---

# 4ï¸âƒ£ Loading Processed Data into SQL

Each fact/dimension load is handled by ADF using simple Copy Activities:

### âœ” Example: Hospital Admissions (Daily)

![SQL hospital load](assets/Screenshot%202025-11-14%20232705.png)

### âœ” Example: Cases & Deaths

![SQL cases load](assets/Screenshot%202025-11-14%20232646.png)

### âœ” Example: Testing Data

![SQL testing load](assets/Screenshot%202025-11-14%20232625.png)

---

# 5ï¸âƒ£ Orchestration & Automation

A master pipeline runs all ingestion and transformations:

- Input ingestion
- Transformations (ADF Data Flows + Databricks)
- SQL load
- Power BI refresh trigger (optional)

### âœ” Trigger

Pipeline is scheduled using:

- **Daily Schedule Trigger**
- **Tumbling Window Trigger (for backfills)**

---

# 6ï¸âƒ£ Monitoring & Alerting

### âœ” ADF Monitor

- Pipeline run views
- Activity failures
- Trigger history

### âœ” Log Analytics + Alerts

Alerts configured for:

- Pipeline failures
- Pipeline duration threshold
- Missing files

---

## 7ï¸âƒ£ Power BI Dashboard â€“ Covid-19 Trends

Located in:

`power_bi_reports/Covid-19 Trends By Country.pbix`

### **Dashboard Includes:**

- Country-wise Covid-19 spread  
- Daily & weekly cases  
- ICU & hospital occupancy  
- Testing volume & positivity rate  
- Age-group impact analytics  
- Multi-country comparison  

---

## ğŸ“Š End-to-End Project Flow (Summary)

### âœ” **Extract**

- HTTP API â†’ ADLS  
- Blob Storage â†’ ADLS  

### âœ” **Validate**

- File existence  
- Column count check  
- Metadata checks  

### âœ” **Transform**

- ADF Data Flows â†’ pivot, aggregate, filter  
- Databricks â†’ heavy transformations  

### âœ” **Load**

- ADLS â†’ Azure SQL Database (Star Schema)  

### âœ” **Visualize**

- Azure SQL â†’ Power BI Dashboards  

